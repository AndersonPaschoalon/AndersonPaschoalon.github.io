<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-07-26T02:45:47-03:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Anderson Paschoalon</title><subtitle>A front-end for my academic formation, projects, and some more stuff.</subtitle><author><name>Anderson Paschoalon</name></author><entry><title type="html">Dawn of the Silver Hands</title><link href="http://localhost:4000/dsilhand.html" rel="alternate" type="text/html" title="Dawn of the Silver Hands" /><published>2022-07-01T03:00:00-03:00</published><updated>2022-07-01T03:00:00-03:00</updated><id>http://localhost:4000/dsilhand</id><content type="html" xml:base="http://localhost:4000/dsilhand.html"><![CDATA[<h1 id="dsilhand">DSilHand</h1>]]></content><author><name>Anderson Paschoalon</name></author><category term="Skyrim" /><category term="Creation Kit" /><category term="Papyrus" /><category term="Game Development" /><category term="Mod" /><summary type="html"><![CDATA[Skyrim mod -- Join the Silver Hand faction!]]></summary></entry><entry><title type="html">Quest Dialog Manager</title><link href="http://localhost:4000/quest-dialog-manager.html" rel="alternate" type="text/html" title="Quest Dialog Manager" /><published>2022-06-01T03:00:00-03:00</published><updated>2022-06-01T03:00:00-03:00</updated><id>http://localhost:4000/quest-dialog-manager</id><content type="html" xml:base="http://localhost:4000/quest-dialog-manager.html"><![CDATA[<h1 id="quest-dialog-manager">Quest Dialog Manager</h1>

<p>CK QuestDialogManages is a tool to help manage your quest mod:</p>
<ul>
  <li>Allows the conversion and generation of many audio
files formats (wav, xwm, fuz)</li>
  <li>Allow you easily manage the audios from you mod: listen
to audios, manage file names,and check subtitles;</li>
  <li>Generate beautifull and comprehensive documentation;</li>
  <li>Reusable Comments and anotations for your documentation.
Regenerate as many times you want with no loss.</li>
</ul>]]></content><author><name>Anderson Paschoalon</name></author><category term="Skyrim" /><category term="Mod" /><category term="Desktop" /><category term="Python" /><summary type="html"><![CDATA[Computer Program Registration Certificate.]]></summary></entry><entry><title type="html">Md2Html</title><link href="http://localhost:4000/md2Html.html" rel="alternate" type="text/html" title="Md2Html" /><published>2022-05-27T03:00:00-03:00</published><updated>2022-05-27T03:00:00-03:00</updated><id>http://localhost:4000/md2Html</id><content type="html" xml:base="http://localhost:4000/md2Html.html"><![CDATA[<h1 id="md2html">Md2Html</h1>

<p>Just a simple command line app to convert Markdown files to HTML.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Usage:
        md2html --md &lt;markdown-file&gt; --title &lt;html-title&gt;

Options:
        --md|-m &lt;markdown-file&gt;: path to markdown file
        --title|-t &lt;html-title&gt;: title to the HTML page title
</code></pre></div></div>

<p>Example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.\\Md2Html.exe --md SampleMarkdown.md --title "HTML page title"
</code></pre></div></div>]]></content><author><name>Anderson Paschoalon</name></author><category term="Markdown" /><category term="HTML" /><category term="Bootstrap" /><category term="Python" /><summary type="html"><![CDATA[Md2Html]]></summary></entry><entry><title type="html">Swing Traffic Generator</title><link href="http://localhost:4000/swing.html" rel="alternate" type="text/html" title="Swing Traffic Generator" /><published>2022-05-27T03:00:00-03:00</published><updated>2022-05-27T03:00:00-03:00</updated><id>http://localhost:4000/swing</id><content type="html" xml:base="http://localhost:4000/swing.html"><![CDATA[<h1 id="swingxficgenerator-v032">Swingxficgenerator (v0.3.2)</h1>

<p>This is a re-upload for the Swing Traffic Generator. Its official homepage is located <a href="https://cseweb.ucsd.edu/~kvishwanath/Swing/"><strong>HERE</strong></a>.</p>

<p>The swing traffic generator is a tool used in the publication <em>Swing: Realistic and Responsive Network Traffic Generation</em>. But the original source code has a compilation error, and I fixed it.</p>

<p>I tried to contact the author some times by email, but with no response. If the author, or anyone related with the project find this repository, please, contact me.</p>

<p>Since the Author <a href="AUTHORS"><strong>Kashi Venkatesh Vishwanath</strong></a> allowed to redistribute the code, according to its <a href="LICENSE"><strong>LICENCE</strong></a> I decided publish it here, so anyone can use this tool.</p>

<p>The original readme file, with a quick introduction, can be found <a href="README"><strong>here</strong></a>.</p>

<p>If you use <strong>Swingxficgenerator</strong> in any work, please, cite the original paper. I also recomment the reading for a deeper undertanding of the tool.</p>

<blockquote>
  <p><strong>Plain Text</strong></p>
  <blockquote>
    <p>K. V. Vishwanath and A. Vahdat, “Swing: Realistic and Responsive Network Traffic Generation,” in IEEE/ACM Transactions on Networking, vol. 17, no. 3, pp. 712-725, June 2009, doi: 10.1109/TNET.2009.2020830.</p>
  </blockquote>
</blockquote>

<blockquote>
  <p><strong>BibTeX</strong></p>
  <blockquote>
    <p><code class="language-plaintext highlighter-rouge">@ARTICLE{4914755,
  author={Vishwanath, Kashi Venkatesh and Vahdat, Amin},
  journal={IEEE/ACM Transactions on Networking}, 
  title={Swing: Realistic and Responsive Network Traffic Generation}, 
  year={2009},
  volume={17},
  number={3},
  pages={712-725},
  doi={10.1109/TNET.2009.2020830}}</code></p>
  </blockquote>
</blockquote>

<p>I used this paper in my master thesis and on its paper, so I’m really greatefull for his work.</p>

<p>My thesis can be found here:
<a href="http://repositorio.unicamp.br/acervo/detalhe/1090415?guid=1657351507677&amp;returnUrl=%2fresultado%2flistar%3fguid%3d1657351507677%26quantidadePaginas%3d1%26codigoRegistro%3d1090415%231090415&amp;i=1">SIMITAR: synthetic and realistic network traffic generation</a></p>

<p>And my article “<strong>Automated Selection of Inter-Packet Time Models Through Information Criteria</strong>” here:</p>

<blockquote>
  <p><strong>Plain Text</strong></p>
  <blockquote>
    <p>A. d. S. Paschoalon and C. E. Rothenberg, “Automated Selection of Inter-Packet Time Models Through Information Criteria,” in IEEE Networking Letters, vol. 1, no. 2, pp. 56-59, June 2019, doi: 10.1109/LNET.2019.2905364.</p>
  </blockquote>

  <p><strong>BibTeX</strong></p>
  <blockquote>
    <p>@ARTICLE{8667676,
  author={Paschoalon, Anderson dos Santos and Rothenberg, Christian Esteve},
  journal={IEEE Networking Letters}, 
  title={Automated Selection of Inter-Packet Time Models Through Information Criteria}, 
  year={2019},
  volume={1},
  number={2},
  pages={56-59},
  doi={10.1109/LNET.2019.2905364}}</p>
  </blockquote>
</blockquote>]]></content><author><name>Anderson Paschoalon</name></author><category term="Swing" /><category term="Traffic Generator" /><category term="Traffic Modelling" /><category term="Wavelet" /><summary type="html"><![CDATA[Swing - Realistic and Responsive Network Traffic Generation]]></summary></entry><entry><title type="html">Spear</title><link href="http://localhost:4000/moforgit.html" rel="alternate" type="text/html" title="Spear" /><published>2022-01-25T03:00:00-03:00</published><updated>2022-01-25T03:00:00-03:00</updated><id>http://localhost:4000/moforgit</id><content type="html" xml:base="http://localhost:4000/moforgit.html"><![CDATA[<h1 id="spear-mod-organizer-for-git-versioning">Spear: Mod Organizer for Git Versioning</h1>

<p>MoForGit is a tool that allows you create a Git repository using a Mod Organizer Tools.</p>

<ul>
  <li>
    <p>Allows you to manage different installations of Steam Game in the same Hard Disk;</p>
  </li>
  <li>
    <p>Transform the installation folder into a git repository, and gitignore all the game files – do file versioning of only your mod files.</p>
  </li>
</ul>]]></content><author><name>Anderson Paschoalon</name></author><category term="Skyrim" /><category term="Mod" /><category term="Desktop" /><category term="CSharp" /><summary type="html"><![CDATA[Mod organizer for Git Versioning]]></summary></entry><entry><title type="html">Mod Pack for Age of Mitology</title><link href="http://localhost:4000/mods-age-of-mitology.html" rel="alternate" type="text/html" title="Mod Pack for Age of Mitology" /><published>2021-08-27T03:00:00-03:00</published><updated>2021-08-27T03:00:00-03:00</updated><id>http://localhost:4000/mods-age-of-mitology</id><content type="html" xml:base="http://localhost:4000/mods-age-of-mitology.html"><![CDATA[<h1 id="mod-pack-for-age-of-mitology">Mod Pack for Age of Mitology</h1>

<p>Some small mods I developed for Age Of Mitology. Right now I have seven random maps, and one Campaing with five scenarios (in development).</p>

<h3 id="random-maps">Random Maps</h3>

<ul>
  <li><strong>Arabian Desert</strong>: A large desert with hidden treasures and bandit camps and scarse wood.</li>
  <li><strong>Elysius Camps</strong>: A miraculous and brilliant land, with plenty of resources available, but you will have to fight for it.</li>
  <li><strong>Guardians A</strong>: Each player starts with a Guardian in the Valley of the Kings.</li>
  <li><strong>Guardians B</strong>: Each player starts with a Guardian in a Savanna megalopolis.</li>
  <li><strong>One Settlement</strong>: All players start with one settlement and some small villages. But there are no other settlements available.</li>
  <li><strong>Ragnarock</strong>: A Battle Royale among the gods in a nordic apocalyptic World.</li>
  <li><strong>Sahara Desert</strong>: All resources are hard to be found in this map, especially wood.</li>
</ul>]]></content><author><name>Anderson Paschoalon</name></author><category term="Age of Mitology" /><category term="Game Development" /><category term="Mod" /><summary type="html"><![CDATA[Pack of small mods for Age of Mitology]]></summary></entry><entry><title type="html">Tabletop RPG Soundtrack</title><link href="http://localhost:4000/tabletop.html" rel="alternate" type="text/html" title="Tabletop RPG Soundtrack" /><published>2021-08-01T03:00:00-03:00</published><updated>2021-08-01T03:00:00-03:00</updated><id>http://localhost:4000/tabletop</id><content type="html" xml:base="http://localhost:4000/tabletop.html"><![CDATA[<h1 id="tabletop-rpg-soundtrack">Tabletop RPG Soundtrack</h1>]]></content><author><name>Anderson Paschoalon</name></author><category term="RPG" /><category term="Tabletop" /><category term="Soundtrack" /><summary type="html"><![CDATA[Tabletop RPG Soundtrack]]></summary></entry><entry><title type="html">Who owns the copyright for an AI generated creative work?</title><link href="http://localhost:4000/AI-and-intellectual-property.html" rel="alternate" type="text/html" title="Who owns the copyright for an AI generated creative work?" /><published>2021-04-20T00:00:00-03:00</published><updated>2021-04-20T00:00:00-03:00</updated><id>http://localhost:4000/AI-and-intellectual-property</id><content type="html" xml:base="http://localhost:4000/AI-and-intellectual-property.html"><![CDATA[<p>Recently I was <a href="https://www.rollingstone.com/music/music-features/nirvana-kurt-cobain-ai-song-1146444/">reading an article</a> about a cool project that intends to have a neural network create songs of the late club of the 27 (artists that have tragically died at age 27 or near, and in the height of their respective careers), artists such as Amy Winehouse, Jimmy Hendrix, Curt Cobain and Jim Morrison.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/GogY7RQFFus" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The project was created by <a href="https://overthebridge.org">Over the Bridge</a>, an organization dedicated to increase awareness on mental health and substance abuse in the music industry, trying to denormalize and remove the glamour around such illnesses within the music community.</p>

<p>They are using Google’s <a href="https://magenta.tensorflow.org">Magenta</a>, which is a neural network that precisely was conceived to explore the role of machine learning within the creative process. Magenta has been used to create a brand new “Beatles” song or even there was a band that <a href="https://arstechnica.com/gaming/2019/08/yachts-chain-tripping-is-a-new-landmark-for-ai-music-an-album-that-doesnt-suck/">used it to write a full album</a> in 2019.</p>

<p>So, while reading the article, my immediate thought was: who owns the copyright of these new songs?</p>

<p>Think about it, imagine one of this new songs becomes a massive hit with millions of youtube views and spotify streams, who can claim the royalties generated?</p>

<p>At first it seems quite simple, <em>Over the Bridge</em> should be the ones reaping the benefits, since they are the ones who had the idea, gathered the data and then fed the neural network to get the “work of art”. But in a second thought, didn’t the original artists provide the basis for the work the neural network generated? shouldn’t their state get credit? what about Google whose tool was used, should they get credit too?</p>

<p>Neural networks have been also used to create poetry, paintings and to write news articles, but how do they do it? A computer program developed for machine learning purposes is an algorithm that “learns” from data to make future decisions. When applied to art, music and literary works, machine learning algorithms are actually learning from some input data to generate a new piece of work, making independent decisions throughout the process to determine what the new work looks like. An important feature of this is that while programmers can set the parameters, the work is actually generated by the neural network itself, in a process akin to the thought processes of humans.</p>

<p>Now, creative works qualify for copyright protection if they are original, with most definitions of originality requiring a human author. Most jurisdictions, including <a href="https://www.wipo.int/wipolex/en/details.jsp?id=1319">Spain</a> and <a href="https://dejure.org/gesetze/UrhG/7.html">Germany</a>, specifically state that only works created by a human can be protected by <a href="https://www.wipo.int/copyright/en/">copyright</a>. In the United States, for example, <a href="https://copyright.gov/comp3/chap300/ch300-copyrightable-authorship.pdf">the Copyright Office has declared</a> that it will “register an original work of authorship, provided that the work was created by a human being.”</p>

<p>So as we currently stand, a human author is required to grant a copyright, which makes sense, there is no point of having a neural network be the beneficiary of royalties of a creative work (no bank would open an account for them anyways, lol).</p>

<p>I think amendments have to be made to the law to ensure that the person who undertook all the arrangements necessary for the work to be created by the neural network gets the credit but also we need to modify copyright law to ensure the original authors of the body of work used as data input to produce the new piece get their corresponding share of credit. This will get messy if someone uses for example the #1 song of every month in a decade to create the decade song, then there would be as many as 120 different artists to credit.</p>

<tweet>In a computer generated artistic work, both the person who undertook all the arrangements necessary for its creation as well as the original authors of the data input need to be credited.</tweet>

<p>There will still be some ambiguity as to who undertook the arrangements necessary, only the one who gathered the data and pressed the button to let the network learn, or does the person who created the neural network’s model also get credit? Shall we go all the way and say that even the programmer of the neural network gets some credit as well?</p>

<p>There are some countries, in particular the UK where some progress has been made to amend copyright laws to cater for computer generated works of art, but I believe this is one of those fields where technology will surpass our law making capacity and we will live under a grey area for a while, and maybe this is just what we need, by having these works ending up free for use by anyone in the world, perhaps a new model for remunerating creative work can be established, one that does not require commercial success to be necessary for artists to make a living, and thus they can become free to explore their art.</p>

<tweet>Perhaps a new model for remunerating creative work can be established, one that does not require commercial success to be necessary for artists to make a living.</tweet>

<p><img src="./assets/img/posts/post8-rembrandt2.jpg" alt="The next Rembrandt" />
<small><a href="https://www.jwt.com/en/work/thenextrembrandt">The Next Rembrandt</a> is a computer-generated 3-D–printed painting developed by a facial-recognition algorithm that scanned data from 346 known paintings by the Dutch painter in a process lasting 18 months. The portrait is based on 168,263 fragments from Rembrandt’s works.</small></p>]]></content><author><name>Armando Maynez</name></author><category term="opinion" /><category term="copyright" /><category term="creativity" /><category term="neural networks" /><category term="machine learning" /><category term="artificial intelligence" /><summary type="html"><![CDATA[As neural networks are used more and more in the creative process, text, images and even music are now created by AI, but who owns the copyright for those works?]]></summary></entry><entry><title type="html">So, what is a neural network?</title><link href="http://localhost:4000/back-to-basics.html" rel="alternate" type="text/html" title="So, what is a neural network?" /><published>2021-04-02T00:00:00-03:00</published><updated>2021-04-02T00:00:00-03:00</updated><id>http://localhost:4000/back-to-basics</id><content type="html" xml:base="http://localhost:4000/back-to-basics.html"><![CDATA[<p>The omnipresence of technology nowadays has made it commonplace to read news about AI, just a quick glance at today’s headlines, and I get:</p>
<ul>
  <li><a href="https://www.morningbrew.com/emerging-tech/stories/2021/03/29/one-biggest-advancements-ai-also-sparked-fierce-debate-heres?utm_source=morning_brew">This Powerful AI Technique Led to Clashes at Google and Fierce Debate in Tech.</a></li>
  <li><a href="https://fortune.com/2021/04/02/ai-forecasting-supply-chain-factories-caterpillar-agco/">How A.I.-powered companies dodged the worst damage from COVID</a></li>
  <li><a href="https://www.mobihealthnews.com/news/emea/ai-technology-detects-ticking-time-bomb-arteries">AI technology detects ‘ticking time bomb’ arteries</a></li>
  <li><a href="https://www.genengnews.com/insights/ai-in-drug-discovery-starts-to-live-up-to-the-hype/">AI in Drug Discovery Starts to Live Up to the Hype</a></li>
  <li><a href="https://www.c4isrnet.com/artificial-intelligence/2021/04/02/pentagon-seeks-commercial-solutions-to-get-its-data-ready-for-ai/">Pentagon seeks commercial solutions to get its data ready for AI</a></li>
</ul>

<p>Topics from business, manufacturing, supply chain, medicine and biotech and even defense are covered in those news headlines, definitively the advancements on the fields of artificial intelligence, in particular machine learning and deep neural networks have permeated into our daily lives and are here to stay. But, do the general population know what are we talking about when we say “an AI”?  I assume most people correctly imagine a computer algorithm or perhaps the more adventurous minds think of a physical machine, an advanced computer entity or even a robot, getting smarter by itself with every use-case we throw at it. And most people will be right, when “an AI” is mentioned it is indeed an algorithm run by a computer, and there is where the boundary of their knowledge lies.</p>

<p>They say that the best way to learn something is to try to explain it, so in a personal exercise I will try to do an ELI5 (<strong>E</strong>xplain it <strong>L</strong>ike <strong>I</strong> am <strong>5</strong>) version of what is a neural network.</p>

<p>Let’s start with a little history, humans have been tinkering with the idea of an intelligent machine for a while now, some even say that the idea of artificial intelligence was conceived by the ancient greeks (<a href="https://www.thinkautomation.com/bots-and-ai/a-history-of-automation-the-rise-of-robots-and-ai/">source</a>), and several attempts at devising “intelligent” machines have been made through history, a notable one was ‘The Analytical Engine’ created by Charles Babbage in 1837:</p>

<p><img src="./assets/img/posts/post7-analytical-engine.jpg" alt="The Analytical Engine" />
<small>The Analytical Engine of Charles Babbage - 1837</small></p>

<p>Then, in the middle of last century by trying to create a model of how our brain works, Neural Networks were born. Around that time, Frank Rosenblatt at Cornell trying to understand the simple decision system present in the eye of a common housefly,  proposed the idea of a <a href="./single-neuron-perceptron.html">perceptron</a>, a very simple system that processes certain inputs with basic math operations and produces an output.</p>

<p><img src="./assets/img/posts/Perceptron.png" alt="A perceptron" /></p>

<p>To illustrate, let’s say that the brain of the housefly is a perceptron, its inputs are whatever values are produced by the multiple cells in its eyes, when the eye cell detects “something” it’s output will be a 1, and if there is nothing a 0. Then the combination of all those inputs can be processed by the perceptron (the fly brain), and the output is a simple 0 or 1 value. If it is a 1 then the brain is telling the fly to flee and if it is a 0 it means it is safe to stay where it is.</p>

<p><img src="./assets/img/posts/post7-housefly-eye.jpg" alt="A housefly eye" /></p>

<p>We can imagine then that if many of the eye cells of the fly produce 1s, it means that an object is quite near, and therefore the perceptron will calculate a 1, it is time to flee.</p>

<p><img src="./assets/img/posts/post7-fly-vision.jpg" alt="The fly vision" /></p>

<p>The perceptron is just a math operation, one that multiplies certain input values with preset “parameters” (called weights) and adds up the resulting multiplications to generate a value.</p>

<p>Then the magic spark was ignited, the parameters (weights) of the perceptron could be “learnt” by a process of minimizing the difference between known results of particular observations, and what the perceptron is actually calculating. It is this process of learning what we call <strong>training the neural network</strong>.</p>

<tweet>This idea is so powerful that even today it is one of the fundamental building blocks of what we call AI.</tweet>

<p>From this I will try to explain how this simple concept can have such diverse applications as natural language processing (think Alexa), image recognition like medical diagnosis from a CTR scan, autonomous vehicles, etc.</p>

<p>A basic neural network is a combination of perceptrons in different arrangements, the perceptron therefore was downgraded from “fly brain” to “network neuron”.
<img src="./assets/img/posts/post7-multilayer-perceptron.png" alt="A multilayer perceptron" /></p>

<p>A neural network has different components, in its basic form it has:</p>
<ul>
  <li>Input</li>
  <li>Hidden layers</li>
  <li>Output</li>
</ul>

<p><img src="./assets/img/posts/nnet_flow.gif" alt="Neural network components" /></p>

<h3 id="input">Input</h3>

<p>The inputs of a neural network are in their essence just numbers, therefore anything that can be converted to a number can become an input. Letters in a text, pixels in an image, frequencies in a sound wave, values from a sensor, etc. are all different things that when converted to a numerical value serve as inputs for the neural network. This is one of the reasons why applications of neural networks are so diverse.</p>

<p>Inputs can be as many as one need for the task at hand, from maybe 9 inputs to teach a neural network how to play tic-tac-toe to thousands of pixels from a camera for an autonomous vehicle. Since the input of a perceptron needs to be a single value, if for example a color pixel is chosen as input, it most likely will be broken into three different values; its  red, green and blue components, hence each pixel will become 3 different inputs for the neural network.</p>

<h3 id="hidden-layers">Hidden layers</h3>

<p>A “layer” within a neural network is just a group of perceptrons that all perform the same exact mathematical operation to the inputs and produce an output. The catch is that each of them have different weights (parameters), therefore their output for a given input will be different amongst them. There are many types of layers, the most typical of them being a “dense” layer, which is another word to say that all the inputs are connected to all the neurons (individual perceptrons), and as said before, each of these connections have a weight associated with it, so that the operation that each neuron performs is a simple weighted sum of all the inputs.</p>

<p><img src="./assets/img/posts/post7-dense-layers.png" alt="post7-dense-layers" /></p>

<p>The hidden layer is then typically connected to another dense layer, and their connection means that each output of a neuron from the first layer is treated effectively as an input for the subsequent one, and it is thus connected to every neuron.</p>

<p>A neural network can have from one to as many layers as one can think, and the number of layers depends solely on the experience we have gathered on the particular problem we would like to solve.</p>

<p>Another critical parameter of a hidden layer is the number of neurons it has, and again, we need to rely on experience to determine how many neurons are needed for a given problem. I have seen networks that vary from a couple of neurons to the thousands. And of course each hidden layer can have as many neurons as we please, so the number of combinations is vast.</p>

<p>To the number of layers, their type and how many neurons each have, is what we call the <em>network topology</em> (including the number of inputs and outputs).</p>

<h3 id="output">Output</h3>

<p>At the very end of the chain, another layer lies (which behaves just like a hidden layer), but has the peculiarity that it is the final layer, and therefore whatever it calculates will be the output values of the whole network. The number of outputs the network has is a function of the problem we would like to solve. It could be as simple as one output, with its value representing a probability of an action (like in the case of the flee reaction of the housefly), to many outputs, perhaps if our network is trying to distinguish images of animals, one would have an output for each animal species, and the output would represent how much confidence the network has that the particular image belongs to the corresponding species.</p>

<p>As we said, the neural network is just a collection of individual neurons, doing basic math operations on certain inputs in series of layers that eventually generate an output. This mesh of neurons is then “trained” on certain output values from known cases of the inputs; once it has learned it can then process new inputs, values that it has never seen before with surprisingly accurate results.</p>

<p>Many of the problems neural networks solve, could be certainly worked out by other algorithms, however, since neural networks are in their core very basic operations, once trained, they are extremely efficient, hence much quicker and economical to produce results.</p>

<p>There are a few more details on how a simple neural network operate that I purposedly left out to make this explanation as simple as possible. Thinks like biases, the activation functions and the math behind learning, the backpropagation algorithm, I will leave to a more in depth article. I will also write (perhaps in a series) about the more complex topologies combining different types of layers and other building blocks, a part from the perceptron.</p>

<p><img src="./assets/img/posts/post7-alexa.png" alt="Alexa recognizing speach" /></p>

<p>Things like “Alexa”, are a bit more complex, but work on exactly the same principles. Let’s break down for example the case of asking “Alexa” to play a song in spotify. Alexa uses several different neural networks to acomplish this:</p>

<h4 id="1-speech-recognition">1. Speech recognition</h4>

<p>As a basic input we have our speech: the command <strong>“Alexa, play Van Halen”</strong>. This might seem quite simple for us humans to process, but for a machine is an incredible difficult feat to be able to understand speech, things like each individual voice timbre, entonation, intention and many more nuances of human spoken language make it so that traditional algorithms have struggled a lot with this. In our simplified example let’s say that we use a neural network to transform our spoken speech into text characters a computer is much more familiarized to learn.</p>

<h4 id="2-understanding-what-we-mean-natural-language-understanding">2. Understanding what we mean (Natural Language Understanding)</h4>

<p>Once the previous network managed to succesfuly convert our spoken words into text, there comes the even more difficult task of making sense of what we said. Things that we humans take for granted such as context, intonation and non verbal communication, help give our words meaning in a very subtle, but powerful way, a machine will have to do with much less information to correctly understand what we mean. It has to correctly identify the intention of our sentence and the subject or entities of what we mean.</p>

<p><img src="./assets/img/posts/post7-alexa-natural-lang.png" alt="post7-alexa-natural-lang" /></p>

<p>The neural network has to identify that it received a command (by identifying its name), the command (“play music”), and our choice (“Van Halen”). And it does so by means of simple math operations as described before. Of course the network involved is quite complex and has different types of neurons and connection types, but the underlying principles remain.</p>

<h4 id="3-replying-to-us">3. Replying to us</h4>

<p>Once Alexa understood what we meant, it then proceeds to execute the action of the command it interpreted and it replies to us in turn using natural language. This is accomplished using a technique called speech synthesis, things like pitch, duration and intensity of the words and phonems are selected based on the “meaning” of what Alexa will respond to us: “Playing songs by Van Halen on Spotify” sounding quite naturally. And all is accomplished with neural networks executing many simple math operations.</p>

<p><img src="./assets/img/posts/post7-alexa-steps.png" alt="post7-alexa-steps" />
<small>Although it seems quite complex, the process for AI to understand us can be boiled down to simple math operations</small></p>

<p>Of course Amazon’s Alexa neural networks have undergone quite a lot of training to get to the level where they are, the beauty is that once trained, to perform their magic they just need a few mathematical operations.</p>

<p>As said before, I will continue to write about the basics of neural networks, the next article in the series will dive a bit deeper into the math behind a basic neural network.</p>]]></content><author><name>Armando Maynez</name></author><category term="theory" /><category term="neural networks" /><category term="machine learning" /><category term="artificial intelligence" /><summary type="html"><![CDATA[ELI5: what is a neural network.]]></summary></entry><entry><title type="html">Starting the adventure</title><link href="http://localhost:4000/starting-the-adventure.html" rel="alternate" type="text/html" title="Starting the adventure" /><published>2021-03-24T00:00:00-03:00</published><updated>2021-03-24T00:00:00-03:00</updated><id>http://localhost:4000/starting-the-adventure</id><content type="html" xml:base="http://localhost:4000/starting-the-adventure.html"><![CDATA[<p>In the midst of a global pandemic caused by the SARS-COV2 coronavirus; I decided to start blogging. I wanted to blog since a long time, I have always enjoyed writing, but many unknowns and having “no time” for it prevented me from taking it up. Things like: “I don’t really know who my target audience is”, “what would my topic or topics be?”, “I don’t think I am a world-class expert in anything”, and many more kept stopping me from setting up my own blog. Now seemed like a good time as any so with those and tons of other questions in my mind I decided it was time to start.</p>

<p>Funnily, this is not my first post. The birth of the blog came very natural as a way to “document” my newly established pursuit for getting myself into Machine Learning. This new adventure of mine comprises several things, and if I want to succeed I need to be serious about them all:</p>
<ul>
  <li>I want to start coding again! I used to code a long time ago, starting when I was 8 years old in a Tandy Color Computer hooked up to my parent’s TV.</li>
  <li>Machine Learning is a vast, wide subject, I want to learn the generals, but also to select a few areas to focus on.</li>
  <li>Setting up a blog to document my journey and share it:</li>
  <li>Establish a learning and blogging routine. If I don’t do this, I am sure this endeavour will die off soon.</li>
</ul>

<p>As for the focus areas I will start with:</p>
<ul>
  <li>Neural Networks fundamentals: history, basic architecture and math behind them</li>
  <li>Deep Neural Networks</li>
  <li>Reinforcement Learning</li>
  <li>Current state of the art: what is at the cutting edge now in terms of Deep Neural Networks and Reinforcement Learning?</li>
</ul>

<p>I selected the above areas to focus on based on my personal interests, I have been fascinated by the developments in reinforcement learning for a long time, in particular <a href="https://deepmind.com/blog">Deep Mind’s</a> awesome <a href="https://deepmind.com/blog/article/innovations-alphago">Go</a>, <a href="https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go">Chess</a> and <a href="https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning">Starcraft</a> playing agents. Therefore, I started reading a lot about it and even started a personal project for coding a <a href="./deep-q-learning-tic-tac-toe.html">tic-tac-toe learning agent</a>.</p>

<p>With my limited knowledge I have drafted the following learning path:</p>

<ol>
  <li>Youtube: <a href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw">Three Blue One Brown’s</a> videos on <a href="https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">Neural Networks</a>, <a href="https://youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Calculus</a> and <a href="https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Linear Algebra</a>. I cannot recommend them enough, they are of sufficient depth and use animation superbly to facilitate the understanding of the subjects.</li>
  <li>Coursera: <a href="https://www.coursera.org/learn/machine-learning">Andrew Ng’s Machine Learning course</a></li>
  <li>Book: <a href="https://www.amazon.com/dp/1617294438/ref=cm_sw_em_r_mt_dp_AV4DHT7CVE95D1SR2JJ8">Deep Learning with Python by Francois Chollet</a></li>
  <li>Book: <a href="https://www.amazon.com/dp/0262193981/ref=cm_sw_em_r_mt_dp_10B6J4MDB7QE3YHBQF4X">Reinforcement Learning: An Introduction, by Richard S. Sutton and Andrew G. Barto</a></li>
</ol>

<p>As for practical work I decided to start by <a href="./ML-Library-from-scratch.html">coding my first models from scratch</a> (without using libraries such as Tensorflow), to be able to deeply understand the math and logic behind the models, so far it has proven to be priceless.</p>

<p>For my next project I think I will start to do the basic hand-written digits recognition, which is the Machine Learning Hello World, for this I think I will start to use Tensorflow already.</p>

<p>I will continue to write about my learning road, what I find interesting and relevant, and to document all my practical exercises, as well as news and the state of the art in the world of AI.</p>

<p>So far, all I have learned has been so engaging that I am seriously thinking of a career change. I have 17 years of international experience in multinational corporations across various functions, such as Information Services, Sales, Customer Care and New Products Introduction, and sincerely, I am finding more joy in artificial intelligence than anything else I have worked on before. Let’s see where the winds take us.</p>

<p>Thanks for reading!</p>

<h3 id="ps-for-the-geeks-like-me-here-is-a-snippet-on-the-technical-side-of-the-blog">P.S. For the geeks like me, here is a snippet on the technical side of the blog.</h3>

<h4 id="static-website-generator">Static Website Generator</h4>
<p>I researched a lot on this, when I started I didn’t even know I needed a static website generator. I was just sure of one thing, I wanted my blog site to look modern, be easy to update and not to have anything extra or additional content or functionality I did not need.</p>

<p>There is a myriad of website generators nowadays, after a lengthy search the ones I ended up considering are:</p>
<ul>
  <li><a href="https://wordpress.com/">wordpress</a></li>
  <li><a href="https://www.wix.com/">wix</a></li>
  <li><a href="https://www.squarespace.com/">squarespace</a></li>
  <li><a href="https://ghost.org/">ghost</a></li>
  <li><a href="https:webflow.com">webflow</a></li>
  <li><a href="https://www.netlify.com/">netlify</a></li>
  <li><a href="https://gohugo.io/">hugo</a></li>
  <li><a href="https://www.gatsbyjs.com/docs/glossary/static-site-generator/">gatsby</a></li>
  <li><a href="https://jekyllrb.com/">jekyll</a></li>
</ul>

<p>I started with the web interfaced generators with included hosting in their offerings:</p>

<p><a href="https://wordpress.com/">wordpress</a> is the old standard, it is the one CMS I knew from before, and I thought I needed a fully fledged CMS, so I blindly ran towards it. Turns out, it has grown a lot since I remembered, it is now a fully fledged platform for complex websites and ecommerce development, even so I decided to give it a try, I picked a template and <a href="https://amaynez.wordpress.com/">created a site</a>. Even with the most simplistic and basic template I could find, there is a lot going on in the site. Setting it up was not as difficult or cumbersome as others claim, it took me about one hour to have it up and running, it looks good, but a bit crowded for my personal taste, and I found out it serves ads in your site for the readers, that is a big no for me.</p>

<p>I have tried <a href="https://www.wix.com/">wix</a> and <a href="https://www.squarespace.com/">squarespace</a> before, they are fantastic for quick and easy website generation, but their free offering has ads, so again, a big no for me.</p>

<p>I discovered <a href="https://ghost.org/">ghost</a> as the platform used by one of the bloggers I follow (<a href="https://ruder.io/">Sebastian Ruder</a>), turns out is a fantastic evolution over wordpress. It runs on the latest technologies, its interface is quite modern, and it is focused on one thing only: publishing. They have a paid hosting service, but the software is open sourced, therefore free to use in any hosting.</p>

<p>I also tested webflow and even created a <a href="https://armando-maynez.webflow.io">mockup</a> there, the learning curve was quite smooth, and its CMS seems quite robust, but a bit too much for the functionalities I required.</p>

<p>Next were the generators that don’t have a web interface, but can be easily set up:</p>

<p>The first I tried was <a href="https://www.netlify.com/">netlify</a>, I also set up a <a href="https://amaynez.netlify.app/">test site</a> in it. Netlify provides free hosting, and to keep your source files it uses GitHub (a repository keeps the source files where it publishes from). It has its own CMS, Netlify CMS, and you have a choice of site generators: Hugo, Gatsby, MiddleMan, Preact CLI, Next.js, Elevently and Nuxt.js, and once you choose there are some templates for each. I did not find the variety of templates enticing enough, and the set up process was much more cumbersome than with wordpress (at least for my knowledge level). I choose Hugo for my test site.</p>

<p>I also tested <a href="https://www.gatsbyjs.com/docs/glossary/static-site-generator/">gatsby</a> with it’s own Gatsby Cloud hosting service, <a href="https://amaynez.gatsbyjs.io/">here is my test site</a>. They also use GitHub as a base to host the source files to build the website, so you create a repository, and it is connected to it. I found the free template offerings quite limited for what I was looking for.</p>

<p>Finally it came the turn for <a href="https://jekyllrb.com/">jekyll</a>, although an older, and slower generator (compared to Hugo and Gatsby), it was created by one of the founders of GitHub, so it’s integration with GitHub Pages is quite natural and painless, so much so, that to use them together you don’t even have to install Jekyll in your machine! You have two choices:</p>
<ol>
  <li>keep it all online, by having one repository in Github keep all the source files, modify or add them online, and having Jekyll build and publish your site to the special <em>gh-pages</em> repository everytime you change or add a new file to the source repository.</li>
  <li>Have a synchronized local copy of the source files for the website, this way you can edit your blog and customize it in your choice of IDE (Integrated Development Environment). Then, when you update any file on your computer, you just “push” the changes to GitHub, and GitHub Pages automatically uses Jekyll to build and publish your site.</li>
</ol>

<p>I chose the second option, specially because I can manipulate files, like images, in my laptop, and everytime I sync my local repository with GitHub, they are updated and published automatically. Quite convenient.</p>

<p>After testing with several templates to get the feel for it, I decided to keep Jekyll for my blog for several reasons: the convenience of not having to install anything extra on my computer to build my blog, the integration with GitHub Pages, the ease of use, the future proofing via integration with modern technologies such as react or vue and the vast online community that has produced tons of templates and useful information for issue resolution, customization and added functionality.</p>

<p>I picked up a template, just forked the repository and started modifying the files to customize it, it was fast and easy, I even took it upon myself to add some functionality to the template (it served as a coding little project) like:</p>
<ul>
  <li>SEO meta tags</li>
  <li>Dark mode (<a href="https://github.com/the-mvm/the-mvm.github.io/blob/a8d4f781bfbc4107b4842433701d28f5bbf1c520/_config.yml#L10">configurable in _config.yml file</a>)</li>
  <li>automatic <a href="http://the-mvm.github.io/sitemap.xml">sitemap.xml</a></li>
  <li>automatic <a href="http://the-mvm.github.io/archive/">archive page</a> with infinite scrolling capability</li>
  <li><a href="https://the-mvm.github.io/tag/?tag=Coding">new page</a> of posts filtered by a single tag (without needing autopages from paginator V2), also with infinite scrolling</li>
  <li>click to tweet functionality (just add a <code class="language-plaintext highlighter-rouge">&lt;tweet&gt; &lt;/tweet&gt;</code> tag in your markdown.</li>
  <li>custom and responsive <a href="https://the-mvm.github.io/404.html">404 page</a></li>
  <li>responsive and automatic Table of Contents (optional per post)</li>
  <li>read time per post automatically calculated</li>
  <li>responsive post tags and social share icons (sticky or inline)</li>
  <li>included linkedin, reddit and bandcamp icons</li>
  <li><em>copy link to clipboard</em> sharing option (and icon)</li>
  <li>view on github link button (optional per post)</li>
  <li>MathJax support (optional per post)</li>
  <li>tag cloud in the home page</li>
  <li>‘back to top’ button</li>
  <li>comments ‘courtain’ to mask the disqus interface until the user clicks on it (<a href="https://github.com/the-mvm/the-mvm.github.io/blob/d4a67258912e411b639bf5acd470441c4c219544/_config.yml#L13">configurable in _config.yml</a>)</li>
  <li><a href="https://github.com/the-mvm/the-mvm.github.io/blob/d4a67258912e411b639bf5acd470441c4c219544/assets/css/main.css#L8">CSS variables</a> to make it easy to customize all colors and fonts</li>
  <li>added several pygments themes for code syntax highlight <a href="https://github.com/the-mvm/the-mvm.github.io/blob/e146070e9348c2e8f46cb90e3f0c6eb7b59c041a/_config.yml#L44">configurable from the _config.yml file</a>. See the <a href="https://github.com/the-mvm/the-mvm.github.io/tree/main/assets/css/highlighter">highlighter directory</a> for reference on the options.</li>
  <li>responsive footer menu and footer logo (<a href="https://github.com/the-mvm/the-mvm.github.io/blob/d4a67258912e411b639bf5acd470441c4c219544/_config.yml#L7">if setup in the config file</a>)</li>
  <li>smoother menu animations</li>
</ul>

<p><img src="./assets/img/template_screenshots/homepage-responsive.jpg" alt="my new blog" /></p>

<p><img src="./assets/img/template_screenshots/light-toggle.png" alt="night theme toggle" /></p>

<p>As a summary, Hugo and Gatsby might be much faster than Jekyll to build the sites, but their complexity I think makes them useful for a big site with plenty of posts. For a small site like mine, Jekyll provides sufficient functionality and power without the hassle.</p>

<p>You can use the modified template yourself by <a href="https://github.com/the-mvm/the-mvm.github.io/fork/">forking my repository</a>. Let me know in the comments or feel free to contact me if you are interested in a detailed walkthrough on how to <a href="https://github.com/the-mvm/the-mvm.github.io#Installation">set it all up</a>.</p>

<h4 id="hosting">Hosting</h4>
<p>Since I decided on Jekyll to generate my site, the choice for hosting was quite obvious, <strong><a href="https://pages.github.com">Github Pages</a></strong> is very nicely integrated with it, it is free, and it has no ads! Plus the domain name isn’t too terrible (<a href="https://the-mvm.github.io">the-mvm.github.io</a>).</p>

<h5 id="interplanetary-file-system">Interplanetary File System</h5>
<p>To contribute to and test <a href="https://github.com/ipfs/ipfs#quick-summary">IPFS</a> I also set up a <a href="https://weathered-bread-8229.on.fleek.co/">mirror</a> in IPFS by using <a href="https://fleek.co">fleek.co</a>. I must confess that it was more troublesome than I imagined, it was definetively not plug and play because of the paths used to fetch resources. The nature of IPFS makes short absolute paths for website resources (like images, css and javascript files) inoperative; the easiest fix for this is to use relative paths, however the same relative path that works for the root directory (i.e. <code class="language-plaintext highlighter-rouge">/index.html</code>) does not work for links inside directories (i.e. <code class="language-plaintext highlighter-rouge">/tags/</code>), and since the site is static, while generating it, one must make the distinction between the different directory levels for the page to be rendered correctly.</p>

<p>At first I tried a simple (but brute force solution):</p>

<pre><code class="language-jekyll"># determine the level of the current file
{% assign lvl = page.url | append:'X' | split:'/' | size %}
# create the relative base (i.e. "../")
{% capture relativebase %}{% for i in (3..lvl) %}../{% endfor %}{% endcapture %}
{% if relativebase == '' %}
	{% assign relativebase = './' %}
{% endif %}
...
# Eliminate unecesary double backslashes
{% capture post_url %}{{ relativebase }}{{ post.url }}{% endcapture %}
{% assign post_url = post_url | replace: "//", "/" %}
</code></pre>

<p>This <code class="language-plaintext highlighter-rouge">jekyll/liquid</code> code was executed in every page (or include) that needed to reference a resource hosted in the same server.</p>

<p>But this fix did not work for the search function, because it relies on a <code class="language-plaintext highlighter-rouge">search.json</code> file (also generated programmatically to be served as a static file), therefore when generating this file one either use the relative path for the <code class="language-plaintext highlighter-rouge">root</code> directory or for a nested directory, thus the search results will only link correctly the corresponding pages if the page where the user searched for something is in the corresponding scope.</p>

<p>So the final solution was to make the whole site flat, meaning to live in a single directory. All pages and posts will live under the root directory, and by doing so, I can control how to address the relative paths for resources.</p>]]></content><author><name>Armando Maynez</name></author><category term="general blogging" /><category term="thoughts" /><category term="life" /><summary type="html"><![CDATA[Midlife career change: a disaster or an opportunity?]]></summary></entry></feed>